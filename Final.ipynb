{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1KM7K8WQ27K"
   },
   "source": [
    "## FINAL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1628351219562,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "Cw6W8TadAmyX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm \n",
    "import tensorflow as tf\n",
    "from  tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import nltk.translate.bleu_score as bleu\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18612,
     "status": "ok",
     "timestamp": 1628350844565,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "guS0Z8RuCwHj",
    "outputId": "8594cafd-93e1-42d2-87b6-c4bb25ab750b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 3791,
     "status": "ok",
     "timestamp": 1628350852016,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "v5xOP5jaCw1J",
    "outputId": "dc486ff6-4eb4-47bc-ed18-744afbe97731"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>y</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and he took in my favorite subject like soccer</td>\n",
       "      <td>and he took in my favorite subjects like soccer</td>\n",
       "      <td>1</td>\n",
       "      <td>and he took in my favorite subjects like soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>actually who let me know about lang  8 was him</td>\n",
       "      <td>actually he was the one who let me know about ...</td>\n",
       "      <td>1</td>\n",
       "      <td>actually he was the one who let me know about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his kanji is ability is much better than me</td>\n",
       "      <td>his kanji ability is much better than mine</td>\n",
       "      <td>1</td>\n",
       "      <td>his kanji ability is much better than mine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "      <td>1</td>\n",
       "      <td>we have known each other for only half a year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i heard a sentence last night when i watched tv</td>\n",
       "      <td>i heard a sentence last night when i was watch...</td>\n",
       "      <td>1</td>\n",
       "      <td>i heard a sentence last night when i was watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505893</th>\n",
       "      <td>hmmm thk i usually book on wkends depends la</td>\n",
       "      <td>hmm i think i usually book on weekends it depends</td>\n",
       "      <td>2</td>\n",
       "      <td>hmm i think i usually book on weekends it depends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505894</th>\n",
       "      <td>ask them got any sms messages to gif me leinow...</td>\n",
       "      <td>can you ask them whether they have for any sms...</td>\n",
       "      <td>2</td>\n",
       "      <td>can you ask them whether they have for any sms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505895</th>\n",
       "      <td>we r near coca oredi</td>\n",
       "      <td>we are near coca already</td>\n",
       "      <td>2</td>\n",
       "      <td>we are near coca already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505896</th>\n",
       "      <td>hall eleven got lectures le mahn forget abt co...</td>\n",
       "      <td>hall eleven got lectures and forget about comp...</td>\n",
       "      <td>2</td>\n",
       "      <td>hall eleven got lectures and forget about comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505897</th>\n",
       "      <td>i bring for u i can not promise u 100 to win s...</td>\n",
       "      <td>i bring for you i can not promise you 100 to w...</td>\n",
       "      <td>2</td>\n",
       "      <td>i bring for you i can not promise you 100 to w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505898 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  ...                                         dec_output\n",
       "0          and he took in my favorite subject like soccer  ...    and he took in my favorite subjects like soccer\n",
       "1          actually who let me know about lang  8 was him  ...  actually he was the one who let me know about ...\n",
       "2             his kanji is ability is much better than me  ...         his kanji ability is much better than mine\n",
       "3       we have known each other for only half a year ...  ...  we have known each other for only half a year ...\n",
       "4         i heard a sentence last night when i watched tv  ...  i heard a sentence last night when i was watch...\n",
       "...                                                   ...  ...                                                ...\n",
       "505893       hmmm thk i usually book on wkends depends la  ...  hmm i think i usually book on weekends it depends\n",
       "505894  ask them got any sms messages to gif me leinow...  ...  can you ask them whether they have for any sms...\n",
       "505895                               we r near coca oredi  ...                           we are near coca already\n",
       "505896  hall eleven got lectures le mahn forget abt co...  ...  hall eleven got lectures and forget about comp...\n",
       "505897  i bring for u i can not promise u 100 to win s...  ...  i bring for you i can not promise you 100 to w...\n",
       "\n",
       "[505898 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/cs2/processed_data.csv\")\n",
    "df.columns = [\"enc_input\",\"dec_input\",\"y\"] \n",
    "df[\"dec_output\"] = df.dec_input\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 23458,
     "status": "ok",
     "timestamp": 1628351844667,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "eY-aByiqUf9c",
    "outputId": "f93e94ba-e0e2-4c71-97b2-1b0d9441c4ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_input</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>y</th>\n",
       "      <th>dec_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144583</th>\n",
       "      <td>you are meeting your friends and going to a ba...</td>\n",
       "      <td>&lt;start&gt; you are meeting your friends and going...</td>\n",
       "      <td>1</td>\n",
       "      <td>you are meeting your friends and going to a ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455599</th>\n",
       "      <td>but since i got here i have not studied a lot</td>\n",
       "      <td>&lt;start&gt; but since i got here i have not studie...</td>\n",
       "      <td>1</td>\n",
       "      <td>but since i got here i have not studied  very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13922</th>\n",
       "      <td>we had lunch with them in a house flooded by t...</td>\n",
       "      <td>&lt;start&gt; we had lunch with those whose house ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>we had lunch with those whose house had been f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128968</th>\n",
       "      <td>an professor introduced me to her</td>\n",
       "      <td>&lt;start&gt; a professor introduced me to her</td>\n",
       "      <td>1</td>\n",
       "      <td>a professor introduced me to her &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402800</th>\n",
       "      <td>his companions were having drinks in front of ...</td>\n",
       "      <td>&lt;start&gt; his companions were having drinks in f...</td>\n",
       "      <td>1</td>\n",
       "      <td>his companions were having drinks in front of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352632</th>\n",
       "      <td>so many people is suffuring from hunger povert...</td>\n",
       "      <td>&lt;start&gt; so many people are suffering from hung...</td>\n",
       "      <td>1</td>\n",
       "      <td>so many people are suffering from hunger and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191449</th>\n",
       "      <td>i wish i could be of some help during this big...</td>\n",
       "      <td>&lt;start&gt; i hope to offer some help in this big ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i hope to offer some help in this big change b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179722</th>\n",
       "      <td>anyway what i hope is he will come to shanghai...</td>\n",
       "      <td>&lt;start&gt; anyway what i hope is that he will com...</td>\n",
       "      <td>1</td>\n",
       "      <td>anyway what i hope is that he will come to sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38604</th>\n",
       "      <td>i just saw something on the facebook</td>\n",
       "      <td>&lt;start&gt; i just saw something on facebook</td>\n",
       "      <td>1</td>\n",
       "      <td>i just saw something on facebook &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388473</th>\n",
       "      <td>and then i started to make my stole with white...</td>\n",
       "      <td>&lt;start&gt; and then i started to knitmyself a sto...</td>\n",
       "      <td>1</td>\n",
       "      <td>and then i started to knitmyself a stole using...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                enc_input  ...                                         dec_output\n",
       "144583  you are meeting your friends and going to a ba...  ...  you are meeting your friends and going to a ba...\n",
       "455599      but since i got here i have not studied a lot  ...  but since i got here i have not studied  very ...\n",
       "13922   we had lunch with them in a house flooded by t...  ...  we had lunch with those whose house had been f...\n",
       "128968                  an professor introduced me to her  ...             a professor introduced me to her <end>\n",
       "402800  his companions were having drinks in front of ...  ...  his companions were having drinks in front of ...\n",
       "...                                                   ...  ...                                                ...\n",
       "352632  so many people is suffuring from hunger povert...  ...  so many people are suffering from hunger and p...\n",
       "191449  i wish i could be of some help during this big...  ...  i hope to offer some help in this big change b...\n",
       "179722  anyway what i hope is he will come to shanghai...  ...  anyway what i hope is that he will come to sha...\n",
       "38604                i just saw something on the facebook  ...             i just saw something on facebook <end>\n",
       "388473  and then i started to make my stole with white...  ...  and then i started to knitmyself a stole using...\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled = pd.concat((df[df.y==1].sample(frac= 0.2,random_state=1),df[df.y==2]))\n",
    "## HERE I AM SAMPLING 1000 POINTS FROM THE DATAFRAME AS TEST DATA WHICH ARE NOT PRESEENT IN THE TRAIN AND VALIDAION DATA\n",
    "np.random.seed(5) \n",
    "df_test = df.loc[np.random.choice(np.array([x for x in df.index.values if x not in df_sampled.index.values]),1000,replace= False,)]\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwqSzwYPWcIw"
   },
   "source": [
    "### Note: The model that i am using in final file is Monotonic Attention model which computes score values by dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1628354837550,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "0Agx9DPeEYk0"
   },
   "outputs": [],
   "source": [
    "def function1(text):\n",
    "    starttime1 = datetime.now()\n",
    "    ## TEXT PREPROCESSING ########\n",
    "    def remove_spaces(text):\n",
    "        text = re.sub(r\" '(\\w)\",r\"'\\1\",text)\n",
    "        text = re.sub(r\" \\,\",\",\",text)\n",
    "        text = re.sub(r\" \\.+\",\".\",text)\n",
    "        text = re.sub(r\" \\!+\",\"!\",text)\n",
    "        text = re.sub(r\" \\?+\",\"?\",text)\n",
    "        text = re.sub(\" n't\",\"n't\",text)\n",
    "        text = re.sub(\"[\\(\\)\\;\\_\\^\\`\\/]\",\"\",text)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def decontract(text):\n",
    "        text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "        text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "        text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'s\", \" is\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'t\", \" not\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'m\", \" am\", text)\n",
    "        return text\n",
    "    def preprocess(text):\n",
    "        text = re.sub(\"\\n\",\"\",text)\n",
    "        text = remove_spaces(text)   # REMOVING UNWANTED SPACES\n",
    "        text = re.sub(r\"\\.+\",\".\",text)\n",
    "        text = re.sub(r\"\\!+\",\"!\",text)\n",
    "        text = decontract(text)    # DECONTRACTION\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]+\",\"\",text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    \n",
    "    text = preprocess(text)\n",
    "\n",
    "\n",
    "    # FORMING TOKENIZED SEQUENCES FOR INPUT SENTENCE\n",
    "    tk_inp = pickle.load(open(\"/content/drive/MyDrive/ColabNotebooks/cs2/final/tk_inp\",\"rb\"))\n",
    "    seq = tk_inp.texts_to_sequences([text])\n",
    "    # PADDING THE SEQUENCES\n",
    "    seq = pad_sequences(seq,maxlen = 20 , padding=\"post\")\n",
    "    tk_out = pickle.load(open(\"/content/drive/MyDrive/ColabNotebooks/cs2/final/tk_out\",\"rb\"))\n",
    "\n",
    "    #### Model #########################\n",
    "    class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "        '''\n",
    "        Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "        '''\n",
    "        \n",
    "        def __init__(self, vocab_size,emb_dims, enc_units, input_length,batch_size):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.emb_dims = emb_dims\n",
    "            self.input_length = input_length\n",
    "            # INITIALIZING THE REQUIRED VARIABLES\n",
    "            self.batch_size=batch_size # BATHCH SIZE\n",
    "            self.enc_units = enc_units # ENCODER UNITS\n",
    "\n",
    "            # EMBEDDING LAYER\n",
    "            self.embedding= layers.Embedding(vocab_size ,emb_dims) \n",
    "            # LSTM LAYER WITH RETURN SEQ AND RETURN STATES\n",
    "            self.lstm = layers.LSTM(self.enc_units,return_state= True,return_sequences =  True) \n",
    "            \n",
    "        def call(self, enc_input , states):\n",
    "            '''\n",
    "            This function takes a sequence input and the initial states of the encoder.\n",
    "            Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "            returns -- encoder_output, last time step's hidden and cell state\n",
    "            '''\n",
    "            # FORMING THE EMBEDDED VECTOR \n",
    "            emb = self.embedding(enc_input)\n",
    "            # PASSING THE EMBEDDED VECTIO THROUGH LSTM LAYERS \n",
    "            enc_output,state_h,state_c = self.lstm(emb,initial_state=states)\n",
    "            #RETURNING THE OUTPUT OF LSTM LAYER\n",
    "            return enc_output,state_h,state_c \n",
    "        \n",
    "        def initialize(self,batch_size):\n",
    "\n",
    "            '''\n",
    "            Given a batch size it will return intial hidden state and intial cell state.\n",
    "            If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "            '''\n",
    "            return tf.zeros(shape=(batch_size,self.enc_units)),tf.zeros(shape=(batch_size,self.enc_units))\n",
    "        def get_config(self):\n",
    "            config = super(Encoder, self).get_config()\n",
    "            config.update({\"vocab_size\":self.vocab_size,\"emb_dims\":self.emb_dims, \"enc_units\":self.enc_units,\"input_length\":self.input_length,\"batch_size\":self.batch_size})\n",
    "            return config\n",
    "\n",
    "    class Monotonic_Attention(tf.keras.layers.Layer):\n",
    "        '''THIS FUNCTION RETURNS THE CONTEXT VECTOR AND ATTENTION WEIGHTS (ALPHA VALUES)'''\n",
    "        def __init__(self,units,att_mode):\n",
    "            super().__init__()\n",
    "            self.units = units\n",
    "            self.att_mode = att_mode\n",
    "            # INITIALIZING THE DENSE LAYER W1\n",
    "            self.W1 = layers.Dense(units)\n",
    "            # INITIALIZING THE DENSE LAYER W2\n",
    "            self.W2 = layers.Dense(units)\n",
    "            # INITIALIZING THE DENSE LAYER V\n",
    "            self.v = layers.Dense(1)\n",
    "            self.mode = att_mode\n",
    "            \n",
    "        def call(self,enc_output,dec_state,prev_att):\n",
    "            # HERE WE ARE COMPUTING THE SCORE \n",
    "\n",
    "            if self.mode == \"dot\":\n",
    "            # FINDING THE SCORE FOR DOT MODEL\n",
    "                dec_state =  tf.expand_dims(dec_state,axis=-1)\n",
    "                score = tf.matmul(enc_output,dec_state)\n",
    "                score = tf.squeeze(score, [2])\n",
    "                \n",
    "                \n",
    "            if self.mode == \"general\":\n",
    "            # FINDING THE SCORE FOR GENERAL MODEL\n",
    "                dec_state =  tf.expand_dims(dec_state,axis=-1)\n",
    "                dense_output = self.W1(enc_output)\n",
    "                score = tf.matmul(dense_output , dec_state)\n",
    "                score = tf.squeeze(score, [2])\n",
    "                \n",
    "                \n",
    "            if self.mode == \"concat\":\n",
    "            # FINDING THE SCORE FOR CONCAT MODEL\n",
    "                dec_state =  tf.expand_dims(dec_state,axis=1)\n",
    "                score = self.v(tf.nn.tanh(\n",
    "                    self.W1(dec_state)+ self.W2(enc_output)))\n",
    "                score = tf.squeeze(score, [2])\n",
    "            \n",
    "            # AFTER THE SOCRES ARE COMPUTED THE SIGMOID IS USED ON IT\n",
    "            probabilities = tf.sigmoid(score)\n",
    "\n",
    "            # ATTENTION WEIGHTS FOR PRESENT TIME STEP\n",
    "            probabilities = probabilities*tf.cumsum(tf.squeeze(prev_att,-1), axis=1)\n",
    "            attention = probabilities*tf.math.cumprod(1-probabilities, axis=1, exclusive=True)\n",
    "            attention = tf.expand_dims(attention,axis=-1)\n",
    "            \n",
    "            # CONTEXT VECTOR\n",
    "            context_vec  =  attention  * enc_output\n",
    "            context_vec = tf.reduce_sum(context_vec,axis=1)\n",
    "            \n",
    "            # RETURN CONTEXT VECTOR AND ATTENTION\n",
    "            return context_vec, attention\n",
    "        def get_config(self):\n",
    "            config = super(Monotonic_Attention, self).get_config()\n",
    "            config.update({\"units\":self.units,\"att_mode\":self.att_mode})\n",
    "            return config\n",
    "\n",
    "    class Onestepdecoder(tf.keras.Model):\n",
    "        '''THIS MODEL OUTPUTS THE RESULT OF DECODER FOR ONE TIME SETP GIVEN THE INPUT FOR PRECIOVE TIME STEP'''\n",
    "    \n",
    "        def __init__(self, vocab_size,emb_dims, dec_units, input_len,att_units,batch_size, att_mode):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.emb_dims = emb_dims\n",
    "            self.dec_units = dec_units\n",
    "            self.input_len = input_len\n",
    "            self.att_units = att_units\n",
    "            self.batch_size = batch_size\n",
    "            self.att_mode = att_mode\n",
    "\n",
    "            # INTITALIZING THE REQUIRED VARIABLES\n",
    "            # EMBEDDING LAYERS\n",
    "            self.emb = layers.Embedding(vocab_size,emb_dims,input_length= input_len)\n",
    "            # ATTENTION LAYER\n",
    "            self.att = Monotonic_Attention(att_units,att_mode)\n",
    "            # LSTM LAYER\n",
    "            self.lstm = layers.LSTM(dec_units,return_sequences=True,return_state=True)\n",
    "            # DENSE LAYER\n",
    "            self.dense = layers.Dense(vocab_size,activation=\"softmax\")\n",
    "\n",
    "        def call(self, encoder_output , input , state_h,state_c,previous_attention):\n",
    "            # FORMING THE EMBEDDED VECTOR FOR THE WORD\n",
    "            # (32,1)=>(32,1,12)\n",
    "            emb = self.emb(input)\n",
    "\n",
    "            dec_output,dec_state_h,dec_state_c = self.lstm(emb, initial_state = [state_h,state_c] )\n",
    "\n",
    "            # GETTING THE CONTEXT VECTOR AND ATTENTION WEIGHTS BASED ON THE ENCODER OUTPUT AND  DECODER STATE_H\n",
    "            context_vec,alphas = self.att(encoder_output,dec_state_h,previous_attention)\n",
    "            \n",
    "            # CONCATINATING THE CONTEXT VECTOR(BY EXPANDING DIMENSION) AND ENBEDDED VECTOR\n",
    "            dense_input =  tf.concat([tf.expand_dims(context_vec,1),dec_output],axis=-1)\n",
    "            \n",
    "            # PASSING THE DECODER OUTPUT THROUGH DENSE LAYER WITH UNITS EQUAL TO VOCAB SIZE\n",
    "            fc = self.dense(dense_input)\n",
    "            \n",
    "            # RETURNING THE OUTPUT\n",
    "            return fc , dec_state_h , dec_state_c , alphas\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            config=({ \"vocab_size\":self.vocab_size,\"emb_dims\":self.emb_dims,\"dec_units\": self.dec_units,\"input_len\": self.input_len,\"att_units\":self.att_units,\"batch_size\":self.batch_size, \"att_mode\":self.att_mode})\n",
    "            return config\n",
    "\n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "\n",
    "    class Decoder(tf.keras.Model):\n",
    "        '''THIS MODEL PERFORMS THE WHOLE DECODER OPERATION FOR THE COMPLETE SENTENCE'''\n",
    "        def __init__(self, vocab_size,emb_dims, dec_units, input_len,att_units,batch_size,att_mode):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.emb_dims = emb_dims\n",
    "            self.dec_units = dec_units\n",
    "            \n",
    "            self.att_units = att_units\n",
    "            self.batch_size = batch_size\n",
    "            self.att_mode = att_mode\n",
    "\n",
    "            # INITIALIZING THE VARIABLES\n",
    "            # LENGTH OF INPUT SENTENCE\n",
    "            self.input_len = input_len\n",
    "            # ONE STEP DECODER\n",
    "            self.onestepdecoder = Onestepdecoder(vocab_size,emb_dims, dec_units, input_len,att_units,batch_size,att_mode)\n",
    "\n",
    "        def call(self,dec_input,enc_output,state_h,state_c,initial_attention):\n",
    "            # THIS VATIABLE STORES THE VALUE OF STATE_H FOR THE PREVIOUS STATE\n",
    "            current_state_h = state_h \n",
    "            current_state_c = state_c\n",
    "            previous_attention = initial_attention\n",
    "            # THIS STORES THE DECODER OUTPUT FOR EACH TIME STEP\n",
    "            pred = []\n",
    "            # THIS STORED THE ALPHA VALUES\n",
    "            alpha_values = []\n",
    "            # FOR EACH WORD IN THE INPUT SENTENCE\n",
    "            for i in range(self.input_len):\n",
    "                \n",
    "                # CURRENT WORD TO INPUT TO ONE STEP DECODER\n",
    "                current_vec = dec_input[:,i]\n",
    "\n",
    "                # EXPANDING THE DIMENSION FOR THE WORD\n",
    "                current_vec = tf.expand_dims(current_vec,axis=-1)\n",
    "\n",
    "                # PERFORMING THE ONE STEP DECODER OPERATION \n",
    "                dec_output,dec_state_h,dec_state_c,alphas = self.onestepdecoder(enc_output ,current_vec,current_state_h,current_state_c,previous_attention)\n",
    "\n",
    "                #UPDATING THE CURRENT STATE_H\n",
    "                current_state_h = dec_state_h\n",
    "                current_state_c = dec_state_c\n",
    "                previous_attention = alphas\n",
    "                \n",
    "                #APPENDING THE DECODER OUTPUT TO \"pred\" LIST\n",
    "                pred.append(dec_output)\n",
    "\n",
    "                # APPENDING THE ALPHA VALUES\n",
    "                alpha_values.append(alphas)\n",
    "                \n",
    "            # CONCATINATING ALL THE VALUES IN THE LIST\n",
    "            output = tf.concat(pred,axis=1)\n",
    "            # CONCATINATING ALL THE ALPHA VALUES IN THE LIST\n",
    "            alpha_values = tf.concat(alpha_values,axis = -1)\n",
    "            # RETURNING THE OUTPUT\n",
    "            return output , alpha_values\n",
    "        def get_config(self):\n",
    "          config = ({ \"vocab_size\":self.vocab_size,\"emb_dims\":self.emb_dims,\"dec_units\": self.dec_units, \"input_len\":self.input_len,\"att_units\":self.att_units,\"batch_size\":self.batch_size,\"att_model\":self.att_mode})\n",
    "          return config\n",
    "\n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    class encoder_decoder(tf.keras.Model):\n",
    "        '''THIS MODEL COMBINES ALL THE LAYERS AND FORM IN ENCODER DECODER MODEL WITH ATTENTION MECHANISM'''\n",
    "        def __init__(self,enc_vocab_size,enc_emb_dim,enc_units,enc_input_length,\n",
    "                dec_vocab_size,dec_emb_dim,dec_units,dec_input_length ,att_units, batch_size,att_mode):\n",
    "            # INITAILIZING ALL VARIABLES\n",
    "            super().__init__()\n",
    "            self.enc_vocab_size= enc_vocab_size\n",
    "            self.enc_emb_dim=enc_emb_dim\n",
    "            self.enc_units= enc_units\n",
    "            self.enc_input_length =enc_input_length\n",
    "            self.dec_vocab_size=dec_vocab_size\n",
    "            self.dec_emb_dim=dec_emb_dim\n",
    "            self.dec_units=dec_units\n",
    "            self.dec_input_length =dec_input_length\n",
    "            self.att_units=att_units\n",
    "            self.att_mode=att_mode\n",
    "\n",
    "            # BATCH SIZE\n",
    "            self.batch_size = batch_size\n",
    "            # INITIALIZING ENCODER LAYER\n",
    "            self.encoder = Encoder(enc_vocab_size, enc_emb_dim,enc_units, enc_input_length,batch_size)\n",
    "            # INITALIZING DECODER LAYER\n",
    "            self.decoder = Decoder(dec_vocab_size ,dec_emb_dim,dec_units,dec_input_length  ,att_units, batch_size,att_mode)\n",
    "            self.input_len = enc_input_length\n",
    "            \n",
    "            \n",
    "        def call(self,data):\n",
    "            # THE INPUT OF DATALOADER IS IN A LIST FORM FOR EACH BATCH IT GIVER TWO INPUTS\n",
    "            # INPUT1 IS FOR ENCODER\n",
    "            # INPUT2 IS FOR DECODER\n",
    "            inp1 , inp2 = data\n",
    "            # PASSING THE INPUT1 TO ENCODER LAYER\n",
    "            enc_output, enc_state_h, enc_state_c = self.encoder(inp1,self.encoder.initialize(self.batch_size))\n",
    "            # PASSING INPUT2 TO THE DECODER LAYER\n",
    "            initial_attention = np.zeros(shape = (self.batch_size,self.input_len,1),dtype=\"float32\")\n",
    "            initial_attention[:,1] = 1 \n",
    "            dec_output , alphas = self.decoder(inp2 , enc_output,enc_state_h,enc_state_c ,initial_attention)\n",
    "            # THE OUTPUT OF MODEL IS ONLY DECODER OUTPUT THE ALPHA VALUES ARE IGNORED HERE\n",
    "            return dec_output\n",
    "\n",
    "        def get_config(self):\n",
    "            config = ({\"enc_vocab_size\":self.enc_vocab_size, \n",
    "                      \"enc_emb_dim\":self.enc_emb_dim,\"enc_units\":self.enc_units,\"enc_input_length\":self.enc_input_length,\\\n",
    "                \"dec_vocab_size\":self.dec_vocab_size,\n",
    "                \"dec_emb_dim\":self.dec_emb_dim,\n",
    "                \"dec_units\":self.dec_units,\n",
    "                \"dec_input_length\":self.dec_input_length ,\\\n",
    "                \"att_units\":self.att_units, \"batch_size\":self.batch_size,\"att_mode\":self.att_mode})\n",
    "            return config\n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "\n",
    "    # INITAILZING THE MODEL\n",
    "    model = encoder_decoder(enc_vocab_size=len(tk_inp.word_index)+1,\n",
    "                            enc_emb_dim = 300,\n",
    "                            enc_units=256,enc_input_length=35,\n",
    "                            dec_vocab_size =len(tk_out.word_index)+1,\n",
    "                            dec_emb_dim =300,\n",
    "                            dec_units=256,\n",
    "                            dec_input_length = 35,\n",
    "                            \n",
    "                            att_units=256,\n",
    "                            batch_size=512,\n",
    "                              att_mode = \"dot\")\n",
    "    model.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy')\n",
    "    model.build([(512,35),(512,35)])\n",
    "    \n",
    "    model.load_weights(\"/content/drive/MyDrive/ColabNotebooks/cs2/model_save/monitonic_attention_dot/best.h5\")\n",
    "\n",
    "    print(\"####### Model Loaded ###########\")\n",
    "    time2 = datetime.now()\n",
    "    print(\"Loading time = \", (time2-starttime1).total_seconds(),\"seconds\")\n",
    "\n",
    "    # INITIALIZING THE STATES FOR INPUTING TO ENCODER\n",
    "    state = model.layers[0].initialize(1)\n",
    "\n",
    "    # GETTING THE ENCODED OUTPUT\n",
    "    enc_output,state_h,state_c= model.layers[0](seq,state)\n",
    "    # VARIABLE TO STORE PREDICTED SENTENCE\n",
    "    pred = []\n",
    "    # THIS VARIABLE STORES THE STATE TO BE INPUTED TO ONE STEP ENCODER\n",
    "    input_state_h = state_h\n",
    "    input_state_c = state_c\n",
    "    prev_attention = np.zeros(shape = (1,20,1),dtype=\"float32\")\n",
    "    prev_attention[:,1] = 1 \n",
    "    # THIS VARIABLE STORES THE VECTOR TO VE INPUTED TO ONE STEP ENCODER\n",
    "    current_vec = tf.ones((1,1))\n",
    "    # THIS VARIABLE WILL STORE ALL THE ALPHA VALUES OUTPUTS\n",
    "    alpha_values = []\n",
    "\n",
    "    for i in range(20):\n",
    "        # PASSING THE REQUIRED VARIABLE TO ONE STEP ENCODER LAYER\n",
    "        fc , dec_state_h ,dec_state_c, alphas = model.layers[1].layers[0](enc_output , current_vec ,input_state_h ,input_state_c,prev_attention)\n",
    "        #APPENDING THE ALPHA VALUES TO THE LIST \"alpha_values\"\n",
    "        alpha_values.append(alphas)\n",
    "         # UPDATING THE CURRENT VECTOR \n",
    "        current_vec = np.argmax(fc , axis = -1)\n",
    "         # UPDATING THE INPUT STATE\n",
    "        input_state_h = dec_state_h\n",
    "        input_state_c = dec_state_c\n",
    "        prev_attention = alphas\n",
    "        # GETTING THE ACTUAL WORDS FRO THE TOKENIZED INDEXES\n",
    "        pred.append(tk_out.index_word[current_vec[0][0]])\n",
    "        # IF THE WORD \"<end>\" COMES THE LOOP WILL BREAK\n",
    "        if tk_out.index_word[current_vec[0][0]]==\"<end>\":\n",
    "              break\n",
    "    # JOINING THE PREDICTED WORDS\n",
    "    pred_sent = \" \".join(pred)\n",
    "    # CONCATINATING ALL THE ALPHA VALUES\n",
    "    alpha_values = tf.squeeze(tf.concat(alpha_values,axis=-1),axis=0)\n",
    "    # RETURNING THE PREDICTED SENTENCE AND ALPHA VALUES\n",
    "    print(\"Predicted Output\",pred_sent)\n",
    "    print(\"=\"*50)\n",
    "    #### Plot for alphas #####\n",
    "    def plot( input_sent , output_sent , alpha ) :\n",
    "        '''THIS FUNCTION PLOTS THE ALPHA VALUES IN FORM OF HEAT MAPS'''\n",
    "      \n",
    "        input_words = input_sent.split() # SPLITTING THE INPUT SENTENCE\n",
    "        output_words = output_sent.split() # SPLITTING THE OUTPUT SENTENCE\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        # HEAT MAP WITH ALPHA VALURS \n",
    "        # X LABELS ARE THE OUTPUT WORDS \n",
    "        # T LABELS ARE THE INPUT WORDS\n",
    "        sns.heatmap(alpha[:len(input_words),:], xticklabels= output_words , yticklabels=input_words,linewidths=0.01)\n",
    "        # PLACING THE TICKS ON  THE TOP\n",
    "        ax.xaxis.tick_top( ) \n",
    "        plt.show()\n",
    "\n",
    "    plot(text,pred_sent,alpha_values)\n",
    "    print(\"=\"*50)\n",
    "    print(\"Prediction time = \", (datetime.now()-time2).total_seconds(),\"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 8522,
     "status": "ok",
     "timestamp": 1628354848065,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "JbQpmesaCw_g",
    "outputId": "350baeaa-2caf-4b21-9138-bf5935470ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Model Loaded ###########\n",
      "Loading time =  8.008193 seconds\n",
      "Predicted Output i found that some of my friends had been here <end>\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Prediction time =  0.378023 seconds\n"
     ]
    }
   ],
   "source": [
    "function1(df_test.enc_input.values[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 8203,
     "status": "ok",
     "timestamp": 1628351982859,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "IJWairFBVXnv",
    "outputId": "9bfc9640-f299-4ad6-f558-bb72fa02aed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Model Loaded ###########\n",
      "Loading time =  8.395404 seconds\n",
      "Predicted Output but he understood the meanings <end>\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD+CAYAAAAppDI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df1RUdf4/8OfwK0XFRdHBhHU1CA3wtyc7urGirAcRUMkQE8zVrSzSUmQVw1P4M3/kiqYuq+ExTClSEdCThqbfagNTDH9EaIoCCu4iG8gg49x5f//w02yEMnd04N6h58Nzz5k78573fc3lyovX+33nXo0QQoCIiMgMO6UDICIi28CEQUREsjBhEBGRLEwYREQkCxMGERHJwoRBRESyMGG0kLKyMowfP152+7y8PJw+fboFI5LP0thbS3R0NM6ePfvI/Vh7Xw8aNEhWu5qaGuzatcsUw8svv2y1GNRi8eLFuHTpktJhPDRrHWNtFROGSuTn56OgoEDpMNoUSZLu+7xS+7qmpga7d+9u9e22puXLl8PLy6tVt6nX66HT6aze708//WT1Pm2dg9IBtGUGgwHz58/HhQsX4O3tjXfffRchISHIyMhAly5dcPbsWaxevRorV67Enj17YGdnhwMHDiAxMRFDhw5VNHZJkvDWW2+hoKAAWq0Wmzdvxs2bN/HOO++guroa7dq1w9KlS/HEE0/I7rOsrAyvvPIKsrOzAQDbt2+HTqdDfn4++vfvj7y8PNTW1mL58uUYOnQo7ty5g0WLFqGoqAh9+vTBnTt3TH19+eWX2LhxI/R6PTw9PbFy5Up06NABgYGBCA4Oxtdff41Zs2ahqqoKe/bsgb29Pby8vDB//vwm+9rd3R0JCQmorq5Gly5dsHLlSjz++OMoKyu77/OlpaWIi4uDTqdDYGCg7M+/bt06XLt2DeHh4XBwcICzszPmzJmD4uJi+Pr6Yu3atdBoNDh37hxWrVoFnU4HV1dXrFy5Et27d5f/w/vVPp81axYGDhyIgoIC+Pn5ISIiAsnJybh16xbWrl0LLy8vLF26FBcvXoTBYEBsbCzGjBmDsrIyxMfHo76+HgCQmJiIwYMHIy8vD5s2bYKrq2uT2KOjoxEfHw9/f38MGjQIMTExOHbsGNq1a4fNmzfDzc0N165dQ1xcHOrr6xEYGIidO3eioKAAN2/exJtvvonbt29DkiS8/fbbzf4/+PHHH/HJJ5/g8OHD2LRpE5566qkH7rvo6GiLj7HXXnsNHTt2xOTJkxEQEAAHB/66hKAWUVpaKp588knx7bffCiGEWLhwodi2bZsYNWqUqKqqEkIIUVhYKKZNmyaEECI5OVls27ZNsXh/qbS0VPTr109cuHBBCCHEnDlzxP79+0VMTIy4cuWKEEKIM2fOiOjoaIv7DQkJMa1v27ZNJCcni2nTpomVK1cKIYT44osvxPTp04UQQnzwwQdi4cKFQgghvv/+e9GvXz9RWFgoqqqqxNSpU0VdXZ0QQoh//OMfYuPGjUIIIUaNGiVSUlJM2xgxYoRoaGgQQgjx008/CSGa7uuXX35Z7N27VwghxCeffCJmz55t9vl9+/YJIYRIS0sTAwcOtPjzf/PNN2Lw4MHixo0bQpIk8fzzz4uTJ08KvV4vIiMjTcdITk6OaR88jJ9/lkVFRUKSJDFx4kSxcOFCYTQaxZEjR8Ts2bPFunXrxP79+0376M9//rOoq6sTOp1O3LlzRwghxJUrV8TEiRObjV0IIaZNmyYKCwuFEEI8+eSTIjc3VwghxLvvvivef/99IYQQL730ksjKyhJCCPHRRx+Z9t/27dvF5s2bhRBCGAwGUVtb2+Tz1NXViYyMDDFlyhQxZcoU8fHHH5vaNbfvLD3GhBDCaDSKb775RixYsEAEBQWJdevWiZKSkof+WbQFTJktqEePHhgyZAgAICwsDB9++KHCEcnn4eGBfv36AQB8fX1RXl6OgoICzJ0719RGr9dbbXtBQUGNtgUAJ0+eRHR0NACgb9++8PHxAQB89913uHTpEqKiogAAd+/excCBA019jRs3zvTYx8cHcXFxGD16NMaMGXPfbRcUFGDjxo0AgPDwcKxZs8ai59euXftQn7l///5wd3c3fb7y8nK4uLiguLgYM2bMAAAYjUZ069btofr/mYeHh2nfeXl54ZlnnoFGo4GPjw/Ky8tRUVGBo0eP4oMPPgAANDQ04MaNG+jevTuSkpJQVFQEOzs7lJSUNBv7r6sBR0dHjBo1CgDg5+eHr776CgBw5swZvP/++wCA0NBQrF69GgDg7++PhIQEGAwGjBkzxnT8/dLIkSPh4+ODZcuWNalur1y50uy+s+QYAwCNRoOnn34aTz/9NG7fvo1//vOfCA4Oxvr16zF27Fh5O7+NYcJoQRqNpsm6vb09xP9dvquhoUGJsGRxcnIyPba3t0dVVRVcXFyQmZn50H06ODjAaDSa1n/5+X/enp2d3QPnHn4mhMCIESPw3nvv3ff19u3bmx6npKTg5MmTOHbsGLZu3YqsrKyHjv+Xfv2zfRi/3seSJEEIAW9vb6Snpz9y//fbjp2dnWldo9FAkiTY29sjOTkZffr0afS+jRs3ws3NDZmZmTAajejfv3+zsf+ao6OjaT/J+bkOGzYMaWlpOH78OBYuXIgZM2ZgwoQJjdokJycjIyMDr7/+OsaNG4eJEyeiZ8+eAGB231lyjP3szp07OHLkCD799FPU1NRg8eLFGDFihKz3tkWc9G5B169fN02uZmdnY8iQIejZsyfOnTsHADh8+LCpbYcOHVBXV6dInHJ07NgRHh4eOHToEIB7/zmLioos6qNr166oqqpCdXU19Ho9vvjii2bbDxs2zDTfUVxcjB9++AEAMHDgQJw+fRpXr14FAOh0Oly5cqXJ+41GI27cuIHhw4cjLi4OtbW10Ol0Tfb1oEGDkJOTAwDIysoy/aUs5/kDBw7I/vxyfsa9e/fGrVu3TMfN3bt3cfHiRdnbeBgjR45EWlqa6Q+ZCxcuAABqa2vRrVs32NnZITMzU/YvWXMGDBhgOvZ/3o8AUF5eDjc3Nzz//POYPHkyzp8/f99Y//73v2PXrl3o1KkTXn31Vbz44osoKyt7qH33oGMMAFavXo1x48ahoKAA8fHx2Lt3L1544QV07NjxkfeBrWLCaEG9e/fGrl27EBwcjJqaGkRFRSE2NhYrVqzApEmTYG9vb2o7atQoHDlyBOHh4fj2228VjPrB1qxZg4yMDISFhSEkJASff/65Re93dHTEa6+9hsmTJ2PGjBlN/qL9taioKOh0OgQHByM5ORm+vr4AYJqAnjdvHkJDQxEZGYnLly83eb8kSViwYAFCQ0MxceJExMTEwMXFpcm+TkxMxN69exEaGorMzEwsXrwYAB74/OLFi/HRRx8hNDQUlZWVsj+/q6srBg8ejPHjx5uGYX7NyckJycnJWLt2LcLCwjBhwoQWP6Pr1VdfhcFgMP1cN2zYAACYOnUq9u3bh7CwMFy+fBnOzs5W2V5CQgJSU1MRGhqKq1evmn4B5+fnIzw8HBMmTMDBgwcRExPzwD5cXV0xffp0ZGZmYt68ebC3t3+offegYwwAnn76aRw6dAhLlizBU089ZZXPbus0QvDy5kTUeurr69GuXTtoNBrk5OQgOzsbW7ZsUToskoFzGETUqs6fP4+kpCQIIeDi4oIVK1YoHRLJxAqDiIhk4RwGERHJwoRBRESyMGEowJrn2LcWxtzybC1egDGr2aJFi/DMM8888EKiQggsW7YMQUFBCA0Nve9pzL/GhKEAWzxgGXPLs7V4AcasZpMmTcK2bdse+PqJEydQUlKCw4cPY+nSpXj77bfN9smEQUTUBg0bNgydO3d+4Ou5ubmYMGECNBoNBg4ciJqaGty8ebPZPnlarQL27t2rdAgWY8wtz9biBRiztd39T9MvoD7I3tyTjaqlyMhIREZGyn5/ZWWl6XpgAODu7o7Kyspmr4zMhGGGg1NPpUOQzaAvt6l4AduL2dbiBRhzazDoy1t9m5YmCGtgwiAiUgujda7XJYdWq0VFRYVpvaKiAlqtttn3cA6DiEgtJIP85REFBgZi//79EELgzJkz6NSpk9kbdbHCICJSCSGM5hvJNG/ePOTn56O6uhrPPvssXn/9dRgM9xJNVFQUAgICcPz4cQQFBaF9+/ayLtHCS4OYYWvjqLYUL2B7MdtavABjbg3WmsPQl52V3dbJw98q27QEKwwiIrWwYoXREpgwiIjUohUnvR8GEwYRkVqwwiAiIjmEFc5+aklMGEREamFkhUFERHJwSIqIiGThpDcREcnCCoOIiGThpDcREcnCSW8iIpJDCM5hEBGRHJzDICIiWVQ+JGXz98MoKyvD+PHjZbfPy8vD6dOnWzAiIqKHJIzyFwX85iqM/Px8ODs7Y/DgwUqHQkTUmHRX6QiaZfMVBgAYDAbMnz8fwcHBmDNnDurr6xEYGIhbt24BAM6ePYvo6GiUlZVhz5492LFjB8LDw/Htt98qHDkR0S8YjfIXBbSJCuPKlStYvnw5hgwZgkWLFuGjjz66bzsPDw9MmTIFzs7OmDlzZitHSURkhsonvdtEhdGjRw8MGTIEABAWFoZTp04pHBER0UNghdHyNBpNk3V7e3v8fPfZhoYGJcIiIrIMz5JqedevX0dBQQEAIDs7G0OGDEHPnj1x7tw5AMDhw4dNbTt06IC6ujpF4iQiao6Q7spelNAmEkbv3r2xa9cuBAcHo6amBlFRUYiNjcWKFSswadIk2Nvbm9qOGjUKR44c4aQ3EamPyk+r1Yifx23ovhyceiodgmwGfblNxQvYXsy2Fi/AmFuDQV9ulX7qc1Nkt20/+iWrbNMSbWIOg4ioTVD5WVJMGEREaqHySW8mDCIitWCFQUREshh4AyUiIpKDFQYREcnCOQwiIpKFFQYREcnCCoOIiGRhhUFERLLwLCkiIpJF5VdqYsIgIlILzmEQEZEsKk8YbeLy5kREbYIVL29+4sQJjB07FkFBQUhJaXoV3OvXryM6OhoTJkxAaGgojh8/brZPVhhERGohSVbqRkJSUhJSU1Oh1Wrx3HPPITAwEF5eXqY2W7ZsQXBwMKZOnYpLly7hpZdewtGjR5vtlwnDDGtd57612Fq8gO3FbGvxAozZZlhpSKqwsBC9evWCp6cnACAkJAS5ubmNEoZGo8Ht27cBALW1tejevbvZfpkwzLj7n8tKhyCbo1sfNJzPVToMizzmO9rmbpRjS/ECjLk1WC25WZAw0tPTkZ6eblqPjIxEZGQkAKCyshLu7u6m17RaLQoLCxu9PzY2FjNnzkRaWhrq6+uRmppqdptMGEREamHBF/d+mSAeRk5ODiZOnIi//OUvKCgoQHx8PLKzs2Fn9+CpbU56ExGphDAK2UtztFotKioqTOuVlZXQarWN2mRkZCA4OBgAMGjQIDQ0NKC6urrZfpkwiIjUwmiUvzTD398fJSUlKC0thV6vR05ODgIDAxu16dGjB/71r38BAH788Uc0NDSgS5cuzfbLISkiIrWw0llSDg4OWLJkCWbNmgVJkhAREQFvb29s2LABfn5+GD16NBYuXIi33noLO3bsgEajwapVq6DRaJrv1yrRERHRo7PiF/cCAgIQEBDQ6Lm5c+eaHnt5eWHPnj0W9cmEQUSkFir/pjcTBhGRWvDig0REJAsrDCIiksXM6bJKY8IgIlILK50l1VKYMIiIVEJwSIqIiGThkBQREcliwbWklMCEQUSkFqwwiIhIFgMnvYmISA4OSRERkSwqH5Jqc5c3Lysrw/jx45UOg4jIYsJolL0ogRUGEZFaqLzCaJMJQ5IkvPXWWygoKIBWq8XmzZtx8+ZNvPPOO6iurka7du2wdOlSPPHEE0qHSkT0PypPGG1uSAoArl69ihdeeAE5OTno1KkTPvvsMyQmJiIxMRF79+7F3/72N7zzzjtKh0lE1JgkyV8U0CYrDA8PD/Tr1w8A4Ovri/LychQUFDS6eYher1cqPCKi+zJ3r26ltcmE4eTkZHpsb2+PqqoquLi4IDMzU8GoiIjMUHnCaJNDUr/WsWNHeHh44NChQwAAIQSKiooUjoqI6FeMRvmLAn4TCQMA1qxZg4yMDISFhSEkJASff/650iERETVmFPIXBbS5ISkPDw9kZ2eb1mfOnGl6vH37diVCIiKSR+VDUm0uYRAR2Soh8dIgREQkBysMIiKSg6fVEhGRPEwYREQki7qnMJgwiIjUQhjUnTGYMIiI1ELd+YIJg4hILTjpTURE8rDCICIiOVhhEBGRPKwwiIhIDmFQOoLmMWEQEamEUHmF8Zu5vDkRkeoZLVjMOHHiBMaOHYugoCCkpKTct83Bgwcxbtw4hISEYP78+Wb7ZIVBRKQS1qowJElCUlISUlNTodVq8dxzzyEwMBBeXl6mNiUlJUhJScHu3bvRuXNnVFVVme2XFQYRkUoIo/ylOYWFhejVqxc8PT3h5OSEkJAQ5ObmNmrz8ccf44UXXkDnzp0BAF27djUbHysMMxzd+igdgkUe8x2tdAgWM+jLlQ7BIrYWL8CYbYWQNLLbpqenIz093bQeGRmJyMhIAEBlZSXc3d1Nr2m1WhQWFjZ6f0lJCQBgypQpMBqNiI2NxbPPPtvsNpkwzHBw6ql0CLIZ9OVw/10/pcOwSMV/v8fd/1xWOgzZHN364LF2nkqHYZGGO6U2dRwD945lW4rZWsnNkiGpXyaIhyFJEq5evYoPP/wQFRUVmDZtGrKysuDi4vLA93BIiohIJYRRI3tpjlarRUVFhWm9srISWq22SZvAwEA4OjrC09MTf/jDH0xVx4MwYRARqYS15jD8/f1RUlKC0tJS6PV65OTkIDAwsFGbMWPGID8/HwBw69YtlJSUwNOz+eqZQ1JERCohhPw5jOY4ODhgyZIlmDVrFiRJQkREBLy9vbFhwwb4+flh9OjR+OMf/4ivvvoK48aNg729PeLj4+Hq6tpsvxohhLovXqIwWxtH5RxGy+IcRuv4rc5hlD0daL7R//HIO2qVbVqCFQYRkUoYLThLSglMGEREKmFuMltpTBhERCrBhEFERLKofUaZCYOISCVYYRARkSzWOq22pTBhEBGphMSzpIiISA5WGEREJAvnMIiISBaeJUVERLKwwiAiIlkko7ovIM6EQUSkEmofkmrxdBYdHY2zZ88+cj95eXk4ffq0FSK6Z9CgQVbri4jIGoxCI3tRgurqH0mS7vt8fn4+CgoKWjkaIqLWI4RG9qIEs0NSZWVleOWVV5CdnQ0A2L59O3Q6HfLz89G/f3/k5eWhtrYWy5cvx9ChQ3Hnzh0sWrQIRUVF6NOnD+7cuWPq68svv8TGjRuh1+vh6emJlStXokOHDggMDERwcDC+/vprzJo1C1VVVdizZw/s7e3h5eWF+fPnY8+ePbCzs8OBAweQmJgId3d3JCQkoLq6Gl26dMHKlSvx+OOPo6ys7L7Pl5aWIi4uDjqdrsmdp4iI1EDtQ1KPNIchSRIyMjJw/PhxbNq0CTt27MDu3bvRrl07HDp0CEVFRZg0aRKAe7cA3LJlC1JTU+Hs7IyUlBSkpqYiNjYWAPC73/0O+/btAwCMHDkSR48ehZOTE2pqauDi4oIpU6bA2dkZM2fOBAC88sormDhxIiZOnIiMjAwsW7YMmzdvxrJly+77/PLlyxEVFYUJEyZg165dj/KxiYhahFJDTXI90pBUUFAQAMDX1xfl5ffuOHXy5EmEhYUBAPr27QsfHx8AwHfffYdLly4hKioK4eHh2L9/P65fv27qa9y4cabHPj4+iIuLQ2ZmJuzt7e+77YKCAowfPx4AEB4ejlOnTpl9PiQkxPQ8EZHaSEY72YsSzFYYDg4OMBr/d8fxhoYG02MnJycAgJ2d3QPnHn4mhMCIESPw3nvv3ff19u3bmx6npKTg5MmTOHbsGLZu3YqsrCxzYcqi0ag7exPRb5vKR6TMVxhdu3ZFVVUVqqurodfr8cUXXzTbftiwYab5juLiYvzwww8AgIEDB+L06dO4evUqAECn0+HKlStN3m80GnHjxg0MHz4ccXFxqK2thU6nQ4cOHVBXV2dqN2jQIOTk5AAAsrKyMHToUNnPHzhwwNzHJiJqdWo/S8psheHo6IjXXnsNkydPhlarRZ8+fZptHxUVhUWLFiE4OBhPPPEEfH19AcA0AT1v3jzo9XoAwBtvvIHevXs3er8kSViwYAFu374NIQRiYmLg4uKCUaNGYc6cOcjNzUViYiISExOxaNEibN++3dQ3gAc+v3jxYsTFxWHbtm2c9CYiVVL7xQc1Qqh9Xl5ZDk49lQ5BNoO+HO6/66d0GBap+O/3uPufy0qHIZujWx881s5T6TAs0nCn1KaOY+DesWxLMRv05Vbp5/+5Pye77R8rMqyyTUvwm95ERCohoO4KgwmDiEglDCofkmLCICJSCVYYREQki9F8E0UxYRARqQQrDCIikoUVBhERySKxwiAiIjlUfodWJgwiIrUwssIgIiI51H7ZDSYMIiKV4KQ3ERHJYlT5LRiYMIiIVKL5uwopT5nbNhERURNGjfzFnBMnTmDs2LEICgpCSkrKA9t99tln8PHxwdmzZ832yYRBRKQSRmhkL82RJAlJSUnYtm0bcnJykJ2djUuXLjVpd/v2bezcuRMDBgyQFR+HpMyw1nXuW0vFf79XOgSLObo1f1MutWm4U6p0CBazteMYsM2YH5W1zpIqLCxEr1694Ol5794tISEhyM3NhZeXV6N2GzZswF//+lds375dVr9MGGbY2k1cbClewPZiNujLcftvk5QOwyId391rU/sYsM3jwhos+eJeeno60tPTTeuRkZGIjIwEAFRWVsLd3d30mlarRWFhYaP3nz9/HhUVFfjTn/7EhEFEZGssOa32lwnC4u0YjVi1apXpFtZyMWEQEamEZKWzarVaLSoqKkzrlZWV0Gq1pvW6ujoUFxcjJiYGAPDvf/8bs2fPxpYtW+Dv7//AfpkwiIhUwlpf3PP390dJSQlKS0uh1WqRk5ODdevWmV7v1KkT8vLyTOvR0dGIj49vNlkATBhERKphrYTh4OCAJUuWYNasWZAkCREREfD29saGDRvg5+eH0aNHP1y/VoqPiIgekTVv6R0QEICAgIBGz82dO/e+bT/88ENZfTJhEBGpBK8lRUREsqj90iBMGEREKsEbKBERkSwckiIiIlmYMIiISBbecY+IiGThHAYREcnCs6SIiEgWo8oHpZgwiIhUgpPeREQki7rrCyYMIiLVUHuFYfP39K6pqcGuXbsAAHl5eXj55ZcVjoiI6OEYNEL2ooQ2kTB2796tdBhERI9MWLAoweaHpNatW4dr164hPDwcDg4OcHZ2xpw5c1BcXAxfX1+sXbsWGo0G586dw6pVq6DT6eDq6oqVK1eie/fuSodPRGTCIakWNn/+fPz+979HZmYm4uPjceHCBSQkJODgwYMoKyvDqVOncPfuXSxbtgzJycnYu3cvIiIisH79eqVDJyJqxAghe1GCzVcYv9a/f3+4u7sDAPr27Yvy8nK4uLiguLgYM2bMAHDvBujdunVTMkwioiZ4llQrc3JyMj22t7eHJEkQQsDb2xvp6ekKRkZE1DwOSbWwDh06oK6urtk2vXv3xq1bt1BQUAAAuHv3Li5evNga4RERySZByF6UYPMVhqurKwYPHozx48fjscceg5ubW5M2Tk5OSE5OxrJly1BbWwtJkjB9+nR4e3srEDER0f2pvcKw+YQB3DtT6n6WLFlietyvXz/T9zWIiNRIqHwWo00kDCKitoAVBhERycKr1RIRkSzqThdMGEREqmFQecpgwiAiUglOehMRkSyc9CYiIllYYRARkSysMIiISBZJsMIgIiIZ+D0MIiKShXMYREQkC+cwiIhIFrUPSdn8/TCIiNoKYcE/c06cOIGxY8ciKCgIKSkpTV5PTU3FuHHjEBoaiunTp6O8vNxsn0wYREQqIQkhe2m2H0lCUlIStm3bhpycHGRnZ+PSpUuN2vTr1w+ffvopsrKyMHbsWKxZs8ZsfEwYREQqYYSQvTSnsLAQvXr1gqenJ5ycnBASEoLc3NxGbYYPH4727dsDAAYOHIiKigqz8XEOwwyD3nyZpia2Fi9gezF3fHev0iFYzNb2MWCbMT8qSya909PTkZ6eblqPjIxEZGQkAKCyshLu7u6m17RaLQoLCx/YV0ZGBp599lmz22TCMMPBqafSIchm0JfbVLyA7cVs0Jcj9g+RSodhkU0l6bh707buYe/Y3dvmjgtrsOS02l8miEeRmZmJc+fOIS0tzWxbJgwiIpWw1llSWq220RBTZWUltFptk3Zff/01tm7dirS0NDg5OZntl3MYREQqIYSQvTTH398fJSUlKC0thV6vR05ODgIDAxu1uXDhApYsWYItW7aga9eusuJjhUFEpBKSlSoMBwcHLFmyBLNmzYIkSYiIiIC3tzc2bNgAPz8/jB49GqtXr4ZOp8PcuXMBAD169MDWrVub79cq0RER0SOz5hf3AgICEBAQ0Oi5n5MDAOzYscPiPpkwiIhUwtxQk9KYMIiIVELtlwZhwiAiUglerZaIiGThDZSIiEgWDkkREZEsTBhERCQLz5IiIiJZWGEQEZEsPEuKiIhkkYS67+rNhEFEpBKcwyAiIlk4h0FERLKofQ7D5u6HsXjx4iY3MyciaguMQshelGBzFcby5cuVDoGIqEWovcJ45IRRVlaGWbNmYeDAgSgoKICfnx8iIiKQnJyMW7duYe3atfDy8sLSpUtx8eJFGAwGxMbGYsyYMSgrK0N8fDzq6+sBAImJiRg8eDDy8vKwadMmuLq6ori4GL6+vli7di00Gg2io6MRHx8Pf39/DBo0CDExMTh27BjatWuHzZs3w83NDdeuXUNcXBzq6+sRGBiInTt3oqCgADdv3sSbb76J27dvQ5IkvP322xg6dOgj70QiImtQ+1lSVhmSunbtGmbMmIFDhw7hypUryMrKwu7duxEfH4+tW7di69atGD58ODIyMrBz506sWbMGOp0OXbt2RWpqKvbt24f169dj2bJlpj4vXLiAhIQEHDx4EGVlZTh16lST7ep0OgwYMCEaez0AAAR4SURBVAAHDhzA0KFD8fHHHwO4V4XExMQgKysL7u7upvbZ2dkYOXIkMjMzkZmZib59+1rj4xMRWcVvYkjKw8MDPj4+AAAvLy8888wz0Gg08PHxQXl5OSoqKnD06FF88MEHAICGhgbcuHED3bt3R1JSEoqKimBnZ4eSkhJTn/379zf9su/bty/Ky8ubVAOOjo4YNWoUAMDPzw9fffUVAODMmTN4//33AQChoaFYvXo1gHv3uU1ISIDBYMCYMWPQr18/a3x8IiKraPNDUgDg5ORkemxnZ2da12g0kCQJ9vb2SE5ORp8+fRq9b+PGjXBzc0NmZiaMRiP69+9/3z7t7e0hSVKT7To6OkKj0Zi2e782vzRs2DCkpaXh+PHjWLhwIWbMmIEJEyZY/oGJiFqAUpWDXK1yltTIkSORlpZm+lLKhQsXAAC1tbXo1q0b7OzskJmZafYXvlwDBgzA4cOHAQA5OTmm58vLy+Hm5obnn38ekydPxvnz562yPSIiaxAW/FNCqySMV199FQaDAWFhYQgJCcGGDRsAAFOnTsW+ffsQFhaGy5cvw9nZ2SrbS0hIQGpqKkJDQ3H16lV07NgRAJCfn4/w8HBMmDABBw8eRExMjFW2R0RkDZKQZC9K0Ai1fxf9IdTX16Ndu3bQaDTIyclBdnY2tmzZ8lB9OTj1tHJ0LcegL7epeAHbi9mgL0fsHyKVDsMim0rScffmRaXDsIhjd2+bOy6s4fdd/GW3vXbrrFW2aQmb+x6GHOfPn0dSUhKEEHBxccGKFSuUDomIyCxeGkQBQ4cOxYEDB5QOg4jIImof8GmTCYOIyBap/SwpJgwiIpX4TXwPg4iIHp3aLw3ChEFEpBKcwyAiIlk4h0FERLKwwiAiIln4PQwiIpKFFQYREcnCs6SIiEgWTnoTEZEsah+SapXLmxMRkXnWvB/GiRMnMHbsWAQFBSElJaXJ63q9Hm+88QaCgoIwefJklJWVme2TCYOISCWEELKX5kiShKSkJGzbts10i4dLly41avPJJ5/AxcUFR44cwYsvvoi1a9eajY9DUmZY6zr3rcXW4gVsL+ZNJelKh2Axx+7eSodgMVs7LqzBWnMYhYWF6NWrFzw9PQEAISEhyM3NhZeXl6nN0aNHERsbCwAYO3as6ZYQP9/2+n6YMIiIVMKSJJmeno709P/98RIZGYnIyHs396qsrIS7u7vpNa1Wi8LCwkbvr6ysRI8ePQAADg4O6NSpE6qrq9GlS5cHbpMJg4jIBv0yQbQWzmEQEbUxWq0WFRUVpvXKykpotdombW7cuAEAMBgMqK2thaura7P9MmEQEbUx/v7+KCkpQWlpKfR6PXJychAYGNioTWBgIPbt2wcA+OyzzzB8+PBm5y8AQCPUfuIvERFZ7Pjx41ixYgUkSUJERARmz56NDRs2wM/PD6NHj0ZDQwMWLFiA77//Hp07d8b69etNk+QPwoRBRESycEiKiIhkYcIgIiJZmDCIiEgWJgwiIpKFCYOIiGRhwiAiIlmYMIiISJb/D1loZw7RWhXLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Prediction time =  0.299987 seconds\n"
     ]
    }
   ],
   "source": [
    "function1(df_test.enc_input.values[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvQAtMNXWW8h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFSxRctpV4xa"
   },
   "source": [
    "#### Observation: We can clearly see that the loading of the model is takin majority of time. Once the model is loaded the predictios takes less than 1 second to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1900,
     "status": "ok",
     "timestamp": 1628355100761,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "4ltQSNP7He5y"
   },
   "outputs": [],
   "source": [
    "def function2(text,actual_output):\n",
    "\n",
    "    ## TEXT PREPROCESSING ### \n",
    "    def remove_spaces(text):\n",
    "        text = re.sub(r\" '(\\w)\",r\"'\\1\",text)\n",
    "        text = re.sub(r\" \\,\",\",\",text)\n",
    "        text = re.sub(r\" \\.+\",\".\",text)\n",
    "        text = re.sub(r\" \\!+\",\"!\",text)\n",
    "        text = re.sub(r\" \\?+\",\"?\",text)\n",
    "        text = re.sub(\" n't\",\"n't\",text)\n",
    "        text = re.sub(\"[\\(\\)\\;\\_\\^\\`\\/]\",\"\",text)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def decontract(text):\n",
    "        text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "        text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "        text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'s\", \" is\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'t\", \" not\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'m\", \" am\", text)\n",
    "        return text\n",
    "    def preprocess(text):\n",
    "        text = re.sub(\"\\n\",\"\",text)\n",
    "        text = remove_spaces(text)   # REMOVING UNWANTED SPACES\n",
    "        text = re.sub(r\"\\.+\",\".\",text)\n",
    "        text = re.sub(r\"\\!+\",\"!\",text)\n",
    "        text = decontract(text)    # DECONTRACTION\n",
    "        text = re.sub(\"[^A-Za-z0-9 ]+\",\"\",text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    \n",
    "    text = preprocess(text)\n",
    "    \n",
    "\n",
    "\n",
    "    # FORMING TOKENIZED SEQUENCES FOR INPUT SENTENCE\n",
    "    tk_inp = pickle.load(open(\"/content/drive/MyDrive/ColabNotebooks/cs2/final/tk_inp\",\"rb\"))\n",
    "    seq = tk_inp.texts_to_sequences([text])\n",
    "    # PADDING THE SEQUENCES\n",
    "    seq = pad_sequences(seq,maxlen = 20 , padding=\"post\")\n",
    "    tk_out = pickle.load(open(\"/content/drive/MyDrive/ColabNotebooks/cs2/final/tk_out\",\"rb\"))\n",
    "\n",
    "    #### Model #########################\n",
    "    class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "        '''\n",
    "        Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
    "        '''\n",
    "        \n",
    "        def __init__(self, vocab_size,emb_dims, enc_units, input_length,batch_size):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.emb_dims = emb_dims\n",
    "            self.input_length = input_length\n",
    "            # INITIALIZING THE REQUIRED VARIABLES\n",
    "            self.batch_size=batch_size # BATHCH SIZE\n",
    "            self.enc_units = enc_units # ENCODER UNITS\n",
    "\n",
    "            # EMBEDDING LAYER\n",
    "            self.embedding= layers.Embedding(vocab_size ,emb_dims) \n",
    "            # LSTM LAYER WITH RETURN SEQ AND RETURN STATES\n",
    "            self.lstm = layers.LSTM(self.enc_units,return_state= True,return_sequences =  True) \n",
    "            \n",
    "        def call(self, enc_input , states):\n",
    "            '''\n",
    "            This function takes a sequence input and the initial states of the encoder.\n",
    "            Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
    "            returns -- encoder_output, last time step's hidden and cell state\n",
    "            '''\n",
    "            # FORMING THE EMBEDDED VECTOR \n",
    "            emb = self.embedding(enc_input)\n",
    "            # PASSING THE EMBEDDED VECTIO THROUGH LSTM LAYERS \n",
    "            enc_output,state_h,state_c = self.lstm(emb,initial_state=states)\n",
    "            #RETURNING THE OUTPUT OF LSTM LAYER\n",
    "            return enc_output,state_h,state_c \n",
    "        \n",
    "        def initialize(self,batch_size):\n",
    "\n",
    "            '''\n",
    "            Given a batch size it will return intial hidden state and intial cell state.\n",
    "            If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
    "            '''\n",
    "            return tf.zeros(shape=(batch_size,self.enc_units)),tf.zeros(shape=(batch_size,self.enc_units))\n",
    "        def get_config(self):\n",
    "            config = super(Encoder, self).get_config()\n",
    "            config.update({\"vocab_size\":self.vocab_size,\"emb_dims\":self.emb_dims, \"enc_units\":self.enc_units,\"input_length\":self.input_length,\"batch_size\":self.batch_size})\n",
    "            return config\n",
    "\n",
    "    class Monotonic_Attention(tf.keras.layers.Layer):\n",
    "        '''THIS FUNCTION RETURNS THE CONTEXT VECTOR AND ATTENTION WEIGHTS (ALPHA VALUES)'''\n",
    "        def __init__(self,units,att_mode):\n",
    "            super().__init__()\n",
    "            self.units = units\n",
    "            self.att_mode = att_mode\n",
    "            # INITIALIZING THE DENSE LAYER W1\n",
    "            self.W1 = layers.Dense(units)\n",
    "            # INITIALIZING THE DENSE LAYER W2\n",
    "            self.W2 = layers.Dense(units)\n",
    "            # INITIALIZING THE DENSE LAYER V\n",
    "            self.v = layers.Dense(1)\n",
    "            self.mode = att_mode\n",
    "            \n",
    "        def call(self,enc_output,dec_state,prev_att):\n",
    "            # HERE WE ARE COMPUTING THE SCORE \n",
    "\n",
    "            if self.mode == \"dot\":\n",
    "            # FINDING THE SCORE FOR DOT MODEL\n",
    "                dec_state =  tf.expand_dims(dec_state,axis=-1)\n",
    "                score = tf.matmul(enc_output,dec_state)\n",
    "                score = tf.squeeze(score, [2])\n",
    "                \n",
    "                \n",
    "            if self.mode == \"general\":\n",
    "            # FINDING THE SCORE FOR GENERAL MODEL\n",
    "                dec_state =  tf.expand_dims(dec_state,axis=-1)\n",
    "                dense_output = self.W1(enc_output)\n",
    "                score = tf.matmul(dense_output , dec_state)\n",
    "                score = tf.squeeze(score, [2])\n",
    "                \n",
    "                \n",
    "            if self.mode == \"concat\":\n",
    "            # FINDING THE SCORE FOR CONCAT MODEL\n",
    "                dec_state =  tf.expand_dims(dec_state,axis=1)\n",
    "                score = self.v(tf.nn.tanh(\n",
    "                    self.W1(dec_state)+ self.W2(enc_output)))\n",
    "                score = tf.squeeze(score, [2])\n",
    "            \n",
    "            # AFTER THE SOCRES ARE COMPUTED THE SIGMOID IS USED ON IT\n",
    "            probabilities = tf.sigmoid(score)\n",
    "\n",
    "            # ATTENTION WEIGHTS FOR PRESENT TIME STEP\n",
    "            probabilities = probabilities*tf.cumsum(tf.squeeze(prev_att,-1), axis=1)\n",
    "            attention = probabilities*tf.math.cumprod(1-probabilities, axis=1, exclusive=True)\n",
    "            attention = tf.expand_dims(attention,axis=-1)\n",
    "            \n",
    "            # CONTEXT VECTOR\n",
    "            context_vec  =  attention  * enc_output\n",
    "            context_vec = tf.reduce_sum(context_vec,axis=1)\n",
    "            \n",
    "            # RETURN CONTEXT VECTOR AND ATTENTION\n",
    "            return context_vec, attention\n",
    "        def get_config(self):\n",
    "            config = super(Monotonic_Attention, self).get_config()\n",
    "            config.update({\"units\":self.units,\"att_mode\":self.att_mode})\n",
    "            return config\n",
    "\n",
    "    class Onestepdecoder(tf.keras.Model):\n",
    "        '''THIS MODEL OUTPUTS THE RESULT OF DECODER FOR ONE TIME SETP GIVEN THE INPUT FOR PRECIOVE TIME STEP'''\n",
    "    \n",
    "        def __init__(self, vocab_size,emb_dims, dec_units, input_len,att_units,batch_size, att_mode):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.emb_dims = emb_dims\n",
    "            self.dec_units = dec_units\n",
    "            self.input_len = input_len\n",
    "            self.att_units = att_units\n",
    "            self.batch_size = batch_size\n",
    "            self.att_mode = att_mode\n",
    "\n",
    "            # INTITALIZING THE REQUIRED VARIABLES\n",
    "            # EMBEDDING LAYERS\n",
    "            self.emb = layers.Embedding(vocab_size,emb_dims,input_length= input_len)\n",
    "            # ATTENTION LAYER\n",
    "            self.att = Monotonic_Attention(att_units,att_mode)\n",
    "            # LSTM LAYER\n",
    "            self.lstm = layers.LSTM(dec_units,return_sequences=True,return_state=True)\n",
    "            # DENSE LAYER\n",
    "            self.dense = layers.Dense(vocab_size,activation=\"softmax\")\n",
    "\n",
    "        def call(self, encoder_output , input , state_h,state_c,previous_attention):\n",
    "            # FORMING THE EMBEDDED VECTOR FOR THE WORD\n",
    "            # (32,1)=>(32,1,12)\n",
    "            emb = self.emb(input)\n",
    "\n",
    "            dec_output,dec_state_h,dec_state_c = self.lstm(emb, initial_state = [state_h,state_c] )\n",
    "\n",
    "            # GETTING THE CONTEXT VECTOR AND ATTENTION WEIGHTS BASED ON THE ENCODER OUTPUT AND  DECODER STATE_H\n",
    "            context_vec,alphas = self.att(encoder_output,dec_state_h,previous_attention)\n",
    "            \n",
    "            # CONCATINATING THE CONTEXT VECTOR(BY EXPANDING DIMENSION) AND ENBEDDED VECTOR\n",
    "            dense_input =  tf.concat([tf.expand_dims(context_vec,1),dec_output],axis=-1)\n",
    "            \n",
    "            # PASSING THE DECODER OUTPUT THROUGH DENSE LAYER WITH UNITS EQUAL TO VOCAB SIZE\n",
    "            fc = self.dense(dense_input)\n",
    "            \n",
    "            # RETURNING THE OUTPUT\n",
    "            return fc , dec_state_h , dec_state_c , alphas\n",
    "\n",
    "\n",
    "        def get_config(self):\n",
    "            config=({ \"vocab_size\":self.vocab_size,\"emb_dims\":self.emb_dims,\"dec_units\": self.dec_units,\"input_len\": self.input_len,\"att_units\":self.att_units,\"batch_size\":self.batch_size, \"att_mode\":self.att_mode})\n",
    "            return config\n",
    "\n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "\n",
    "    class Decoder(tf.keras.Model):\n",
    "        '''THIS MODEL PERFORMS THE WHOLE DECODER OPERATION FOR THE COMPLETE SENTENCE'''\n",
    "        def __init__(self, vocab_size,emb_dims, dec_units, input_len,att_units,batch_size,att_mode):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            self.emb_dims = emb_dims\n",
    "            self.dec_units = dec_units\n",
    "            \n",
    "            self.att_units = att_units\n",
    "            self.batch_size = batch_size\n",
    "            self.att_mode = att_mode\n",
    "\n",
    "            # INITIALIZING THE VARIABLES\n",
    "            # LENGTH OF INPUT SENTENCE\n",
    "            self.input_len = input_len\n",
    "            # ONE STEP DECODER\n",
    "            self.onestepdecoder = Onestepdecoder(vocab_size,emb_dims, dec_units, input_len,att_units,batch_size,att_mode)\n",
    "\n",
    "        def call(self,dec_input,enc_output,state_h,state_c,initial_attention):\n",
    "            # THIS VATIABLE STORES THE VALUE OF STATE_H FOR THE PREVIOUS STATE\n",
    "            current_state_h = state_h \n",
    "            current_state_c = state_c\n",
    "            previous_attention = initial_attention\n",
    "            # THIS STORES THE DECODER OUTPUT FOR EACH TIME STEP\n",
    "            pred = []\n",
    "            # THIS STORED THE ALPHA VALUES\n",
    "            alpha_values = []\n",
    "            # FOR EACH WORD IN THE INPUT SENTENCE\n",
    "            for i in range(self.input_len):\n",
    "                \n",
    "                # CURRENT WORD TO INPUT TO ONE STEP DECODER\n",
    "                current_vec = dec_input[:,i]\n",
    "\n",
    "                # EXPANDING THE DIMENSION FOR THE WORD\n",
    "                current_vec = tf.expand_dims(current_vec,axis=-1)\n",
    "\n",
    "                # PERFORMING THE ONE STEP DECODER OPERATION \n",
    "                dec_output,dec_state_h,dec_state_c,alphas = self.onestepdecoder(enc_output ,current_vec,current_state_h,current_state_c,previous_attention)\n",
    "\n",
    "                #UPDATING THE CURRENT STATE_H\n",
    "                current_state_h = dec_state_h\n",
    "                current_state_c = dec_state_c\n",
    "                previous_attention = alphas\n",
    "                \n",
    "                #APPENDING THE DECODER OUTPUT TO \"pred\" LIST\n",
    "                pred.append(dec_output)\n",
    "\n",
    "                # APPENDING THE ALPHA VALUES\n",
    "                alpha_values.append(alphas)\n",
    "                \n",
    "            # CONCATINATING ALL THE VALUES IN THE LIST\n",
    "            output = tf.concat(pred,axis=1)\n",
    "            # CONCATINATING ALL THE ALPHA VALUES IN THE LIST\n",
    "            alpha_values = tf.concat(alpha_values,axis = -1)\n",
    "            # RETURNING THE OUTPUT\n",
    "            return output , alpha_values\n",
    "        def get_config(self):\n",
    "          config = ({ \"vocab_size\":self.vocab_size,\"emb_dims\":self.emb_dims,\"dec_units\": self.dec_units, \"input_len\":self.input_len,\"att_units\":self.att_units,\"batch_size\":self.batch_size,\"att_model\":self.att_mode})\n",
    "          return config\n",
    "\n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "    class encoder_decoder(tf.keras.Model):\n",
    "        '''THIS MODEL COMBINES ALL THE LAYERS AND FORM IN ENCODER DECODER MODEL WITH ATTENTION MECHANISM'''\n",
    "        def __init__(self,enc_vocab_size,enc_emb_dim,enc_units,enc_input_length,\n",
    "                dec_vocab_size,dec_emb_dim,dec_units,dec_input_length ,att_units, batch_size,att_mode):\n",
    "            # INITAILIZING ALL VARIABLES\n",
    "            super().__init__()\n",
    "            self.enc_vocab_size= enc_vocab_size\n",
    "            self.enc_emb_dim=enc_emb_dim\n",
    "            self.enc_units= enc_units\n",
    "            self.enc_input_length =enc_input_length\n",
    "            self.dec_vocab_size=dec_vocab_size\n",
    "            self.dec_emb_dim=dec_emb_dim\n",
    "            self.dec_units=dec_units\n",
    "            self.dec_input_length =dec_input_length\n",
    "            self.att_units=att_units\n",
    "            self.att_mode=att_mode\n",
    "\n",
    "            # BATCH SIZE\n",
    "            self.batch_size = batch_size\n",
    "            # INITIALIZING ENCODER LAYER\n",
    "            self.encoder = Encoder(enc_vocab_size, enc_emb_dim,enc_units, enc_input_length,batch_size)\n",
    "            # INITALIZING DECODER LAYER\n",
    "            self.decoder = Decoder(dec_vocab_size ,dec_emb_dim,dec_units,dec_input_length  ,att_units, batch_size,att_mode)\n",
    "            self.input_len = enc_input_length\n",
    "            \n",
    "            \n",
    "        def call(self,data):\n",
    "            # THE INPUT OF DATALOADER IS IN A LIST FORM FOR EACH BATCH IT GIVER TWO INPUTS\n",
    "            # INPUT1 IS FOR ENCODER\n",
    "            # INPUT2 IS FOR DECODER\n",
    "            inp1 , inp2 = data\n",
    "            # PASSING THE INPUT1 TO ENCODER LAYER\n",
    "            enc_output, enc_state_h, enc_state_c = self.encoder(inp1,self.encoder.initialize(self.batch_size))\n",
    "            # PASSING INPUT2 TO THE DECODER LAYER\n",
    "            initial_attention = np.zeros(shape = (self.batch_size,self.input_len,1),dtype=\"float32\")\n",
    "            initial_attention[:,1] = 1 \n",
    "            dec_output , alphas = self.decoder(inp2 , enc_output,enc_state_h,enc_state_c ,initial_attention)\n",
    "            # THE OUTPUT OF MODEL IS ONLY DECODER OUTPUT THE ALPHA VALUES ARE IGNORED HERE\n",
    "            return dec_output\n",
    "\n",
    "        def get_config(self):\n",
    "            config = ({\"enc_vocab_size\":self.enc_vocab_size, \n",
    "                      \"enc_emb_dim\":self.enc_emb_dim,\"enc_units\":self.enc_units,\"enc_input_length\":self.enc_input_length,\\\n",
    "                \"dec_vocab_size\":self.dec_vocab_size,\n",
    "                \"dec_emb_dim\":self.dec_emb_dim,\n",
    "                \"dec_units\":self.dec_units,\n",
    "                \"dec_input_length\":self.dec_input_length ,\\\n",
    "                \"att_units\":self.att_units, \"batch_size\":self.batch_size,\"att_mode\":self.att_mode})\n",
    "            return config\n",
    "        @classmethod\n",
    "        def from_config(cls, config):\n",
    "            return cls(**config)\n",
    "\n",
    "    # INITAILZING THE MODEL\n",
    "    model = encoder_decoder(enc_vocab_size=len(tk_inp.word_index)+1,\n",
    "                            enc_emb_dim = 300,\n",
    "                            enc_units=256,enc_input_length=35,\n",
    "                            dec_vocab_size =len(tk_out.word_index)+1,\n",
    "                            dec_emb_dim =300,\n",
    "                            dec_units=256,\n",
    "                            dec_input_length = 35,\n",
    "                            \n",
    "                            att_units=256,\n",
    "                            batch_size=512,\n",
    "                              att_mode = \"dot\")\n",
    "    model.compile(optimizer=\"adam\",loss='sparse_categorical_crossentropy')\n",
    "    model.build([(512,35),(512,35)])\n",
    "    \n",
    "    model.load_weights(\"/content/drive/MyDrive/ColabNotebooks/cs2/model_save/monitonic_attention_dot/best.h5\")\n",
    "\n",
    "\n",
    "    # INITIALIZING THE STATES FOR INPUTING TO ENCODER\n",
    "    state = model.layers[0].initialize(1)\n",
    "\n",
    "    # GETTING THE ENCODED OUTPUT\n",
    "    enc_output,state_h,state_c= model.layers[0](seq,state)\n",
    "    # VARIABLE TO STORE PREDICTED SENTENCE\n",
    "    pred = []\n",
    "    # THIS VARIABLE STORES THE STATE TO BE INPUTED TO ONE STEP ENCODER\n",
    "    input_state_h = state_h\n",
    "    input_state_c = state_c\n",
    "    prev_attention = np.zeros(shape = (1,20,1),dtype=\"float32\")\n",
    "    prev_attention[:,1] = 1 \n",
    "    # THIS VARIABLE STORES THE VECTOR TO VE INPUTED TO ONE STEP ENCODER\n",
    "    current_vec = tf.ones((1,1))\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(20):\n",
    "        # PASSING THE REQUIRED VARIABLE TO ONE STEP ENCODER LAYER\n",
    "        fc , dec_state_h ,dec_state_c, alphas = model.layers[1].layers[0](enc_output , current_vec ,input_state_h ,input_state_c,prev_attention)\n",
    "        #APPENDING THE ALPHA VALUES TO THE LIST \"alpha_values\"\n",
    "        \n",
    "         # UPDATING THE CURRENT VECTOR \n",
    "        current_vec = np.argmax(fc , axis = -1)\n",
    "         # UPDATING THE INPUT STATE\n",
    "        input_state_h = dec_state_h\n",
    "        input_state_c = dec_state_c\n",
    "        prev_attention = alphas\n",
    "        # GETTING THE ACTUAL WORDS FRO THE TOKENIZED INDEXES\n",
    "        pred.append(tk_out.index_word[current_vec[0][0]])\n",
    "        # IF THE WORD \"<end>\" COMES THE LOOP WILL BREAK\n",
    "        if tk_out.index_word[current_vec[0][0]]==\"<end>\":\n",
    "              break\n",
    "    # JOINING THE PREDICTED WORDS\n",
    "    pred_sent = \" \".join(pred)\n",
    "    # CONCATINATING ALL THE ALPHA VALUES\n",
    "\n",
    "    print(\"BLEU Score\",bleu.sentence_bleu([actual_output.split()],pred_sent.split()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnWAzepVXMIk"
   },
   "source": [
    "## Function 2 for some random test datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6863,
     "status": "ok",
     "timestamp": 1628355111004,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "x7JBdj89He2V",
    "outputId": "5b8ebb08-a6df-4baa-92d8-52b0ffc96f50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score 0.587728372510532\n"
     ]
    }
   ],
   "source": [
    "function2(df_test.enc_input.values[5],df_test.dec_output.values[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8175,
     "status": "ok",
     "timestamp": 1628355119170,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "5l8W0LB0CxC3",
    "outputId": "fc0eb36f-0c97-4331-b2ae-5b652cb01400"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score 1.0\n"
     ]
    }
   ],
   "source": [
    "function2(df_test.enc_input.values[50],df_test.dec_output.values[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10720,
     "status": "ok",
     "timestamp": 1628352340024,
     "user": {
      "displayName": "PUSHAP GANDHI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtvSq40Q0iR7PAFnCqNljCvZEL0u3Jwy5L59EZTA=s64",
      "userId": "12599792132870778014"
     },
     "user_tz": -330
    },
    "id": "B9ST2w5ySAxr",
    "outputId": "64fd3ac6-90f7-48cb-9af1-df9b2c7e2a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score 0.5193071778680676\n"
     ]
    }
   ],
   "source": [
    "function2(df_test.enc_input.values[99],df_test.dec_output.values[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0rD_WHrhrJo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOraSGQylPZgUcGkKtbPBTr",
   "collapsed_sections": [],
   "name": "Final",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
